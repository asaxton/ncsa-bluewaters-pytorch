#!/bin/bash
#PBS -l nodes=32:ppn=16:xk
#PBS -l walltime=10:00:00
#PBS -N distributed_cnn_train
#PBS -e logs/log.${PBS_JOBNAME}_NN_${PBS_NUM_NODES}_${PBS_JOBID}.err
#PBS -o logs/log.${PBS_JOBNAME}_NN_${PBS_NUM_NODES}_${PBS_JOBID}.out
#PBS -l flags=commtransparent
#PBS -l advres=baui1
cd $PBS_O_WORKDIR
mkdir -p logs
module load bwpy
module load bwpy-mpi
module load tau
source ~/.virtualenv/pytorch-spring2018/bin/activate
#export MPICH_RMA_OVER_DMAPP=1
#export MPICH_MAX_THREAD_SAFETY=multiple

#aprun -cc none -n 8 -d 16 -N 1 -b -- python \
#    simple_linear_regressin_distributed_train.py
LANG=C.UTF-8 
LC_ALL=C.UTF-8

MODEL="inception_v3"
#MODEL="resnet50"
MBS=32

echo "computing $MODEL"

LEARNING_RATE=$(echo "0.4 * sqrt(${PBS_NUM_NODES})" | bc)
echo "Learning Rate: ${LEARNING_RATE}"
echo "Mini Batch Size $MBS"
DATA_DIR="${HOME}/scratch/ImageNet/class-dir-imagenet/train/Images/"
echo "training on data from ${DATA_DIR}"
CPT_DIR=${HOME}/scratch/pytorch_cpts/${PBS_JOBNAME}_NN_${PBS_NUM_NODES}_${PBS_JOBID}
echo "Checkpoints saved to ${CPT_DIR}"
mkdir -p $CPT_DIR

#aprun -cc none -n 1 -d 16 -N 1 -b -- python \
#aprun -cc none -n $PBS_NUM_NODES -d 16 -N 1 -b -- tau_exec -T mpi -- python \
aprun -cc none -n $PBS_NUM_NODES -d 16 -N 1 -b -- python \
    ../BWDistributedTrain/distributed_cnn_train.py \
    ${DATA_DIR} \
    --batch-size $MBS \
    --learning-rate $LEARNING_RATE \
    --weight-decay 0.1 \
    --momentum 0.9 \
    --num-epochs 100 \
    --num-class 6 \
    --checkpoint ${CPT_DIR} \
    --model $MODEL #\
#    1> ${PBS_O_WORKDIR}/logs/apout.${PBS_JOBNAME}_NN_${PBS_NUM_NODES}_${PBS_JOBID}.out \
#    2> ${PBS_O_WORKDIR}/logs/apout.${PBS_JOBNAME}_NN_${PBS_NUM_NODES}_${PBS_JOBID}.err
